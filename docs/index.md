# Empowering the Danish Language in the Digital Age

Welcome to the Danish Foundation Models (DFM) project, a pioneering initiative in the field of machine learning and natural language processing (NLP) dedicated to the Danish language. Our mission is to develop, maintain, and provide open access to high-quality foundation models tailored for Danish, promoting innovation and inclusivity in language technologies.

## Why Danish Foundation Models?

### Bridging the Digital Language Divide

-  **Global Gap**: The rise of large language models has transformed research and technology, but smaller languages like Danish risk falling behind both in development, evaluation, and application.
-  **Local Focus**: We combat this by focusing on the Danish language, ensuring that it is well-represented in the digital landscape.
-  **Broad Collaboration**: Our project unites public and private institutions, ensuring high data quality and practical applicability of our models.

## Our Objectives  

1. To develop and maintain **state-of-the-art language models for Danish** for applications within both text and speech.
2. To extensively **validate** foundation models for Danish in a representative set of tasks.
3. To maintain a high standard of **documentation** of models such as model cards \[[Mitchell et al., 2019](https://arxiv.org/abs/1810.03993)\] and datasheets \[[Gebru et al., 2021](https://cacm.acm.org/magazines/2021/12/256932-datasheets-for-datasets/abstract)\].
4. To **open-source** not only the models but also all components required for reproducibility such as pre-processing, training, and validation code.

You can read more about the argument for Danish language models in our [publication](inreview).

## Open-source Models on Closed-source Data

Since many of the datasets we use either contain personally sensitive information or are subject to copyright, they cannot be shared publicly. However, we want to share as much as possible from the project while protecting privacy and adhering to copyright law. 
Thus, we organize it such that all parts of the project that can be shared and those that cannot are well-documented using datasheets and training logs. Furthermore, during the data processing and training, the data is stored on UCloud, which follows the highest standards of information security management with a [formal ISO27001 certification](https://docs.cloud.sdu.dk/intro/security.html).

![Project Structure](_static/structure.png)

## Join Us

We invite collaboration and contributions from industry professionals, researchers, and the open-source community. Together, we can advance the field of Danish NLP and create a more inclusive digital future. You can reach out to us using the following channels:

|                                                                                                                      |                                                                    |
| -------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------ |
| ðŸ—£ [**DDSC Slack**](https://join.slack.com/t/danskdatascie-o8m9638/shared_invite/zt-1jh2dwmj4-D_mjywfXERvVP75n9O0ykg) | Join the discussion in the "danish-foundation-models-text" channel |
| ðŸ’¬ [**GitHub Discussion**](https://github.com/centre-for-humanities-computing/danish-foundation-models/discussions)   | Ask questions or start a discussion                                |
| ðŸš¨ [**GitHub Issues**](https://github.com/centre-for-humanities-computing/danish-foundation-models/issues)            | Noticed a bug in the code? Please create an issue                  |
