data_arguments:
    dataset_names: ["wikitext_v1"]
    interleave_datasets: true
    interleave_probabilities: [0.5, 0.5]
    num_proc: 6
    mlm_probability: 0.15

model_arguments:
    model_type: "seq2seq"
    model_name: "t5-small"

training_arguments:
    learning_rate: 0.0005
    do_train: true
    do_eval: true
    push_to_hub: false
    fp16: true
    num_train_epochs: 15
    evaluation_strategy: "epoch"
    output_dir: "models123"
